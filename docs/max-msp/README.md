# Max / MSP Ecosystem

These sections relate to developement for the Max/MSP enviroenemnt (Cycling'74), for audio processing and synthese, and gesture analysis and interactive machine learning.

## MuBu

`MuBu` is a Max toolbox for Multimodal Analysis of Sound and Motion, Sound Synthesis and Interactive Machine Learning. It allows to create interactive gesture-based sonic system, and it's also the base for the CataRT - Corpus based Concatenative Synthesis (presented seperately).

- Available in the Max package manager and by [Ircam Forum](https://forum.ircam.fr/projects/detail/mubu/)

`MuBu` can be used in different typical use cases


### Recording, playing, analyzing and visualizing multidmodal data

```
 - audio and audio descriptors
 - sensors data and motion descriptors
 - MIDI
 - Temporal markers
```

### Real-time processing of audio and sensor data
```
 - filtering
 - segmentation
 - computing descriptors (fft, mfcc, wavelet, statistic)
```

### Interactive Machine Learning
```
 - Knn
 - GMM (recognitio)), GMR (regression)
 - HMM (recognition), XMM (regression); 
 - dtw
 - Gesture following (GF) and Gesture Variation Following
 
```

### Interactive Sound Synthesis
```
 - Granular synthesis
 - Concatenative synthesis
 - Additive synthese 
 
```

> License: Forum (Toolbox distributed freely, proprietary code)

## CataRT

## Max externals for audio

## Max externals for gesture
