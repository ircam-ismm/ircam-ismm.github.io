(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{372:function(e,t,n){e.exports=n.p+"assets/img/research-areas-illustration.d15e088f.jpg"},461:function(e,t,n){"use strict";n.r(t);var a=n(65),r=Object(a.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"sound-music-movement-interaction-team"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sound-music-movement-interaction-team"}},[e._v("#")]),e._v(" {Sound Music Movement} Interaction Team")]),e._v(" "),a("p",[e._v("Welcome our developement documentations pages.")]),e._v(" "),a("p",[e._v("The ISMM Team (IRCAM - CNRS  - Sorbonne Université) conducts research and development on interactive music systems, including gesture and movement interaction, collective interaction and distributed sound systems, and interactive sound synthesis.")]),e._v(" "),a("p",[e._v("The applications focuses on primarly on music, performing arts and sound installation, but also reachs domain such as pedagogy and music education, sound design, to emerging applications such rehabilitation with auditory feedback.")]),e._v(" "),a("p",[e._v("We are currently developing tools and applications for Max/MSP and in Javascript.")]),e._v(" "),a("p",[e._v("Our most recent open-source projects can be found at")]),e._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/ircam-ismm",target:"_blank",rel:"noopener noreferrer"}},[e._v("ircam-ismm@github"),a("OutboundLink")],1)]),e._v(" "),a("li",[a("a",{attrs:{href:"https://forum.ircam.fr/projects/detail/mubu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ircam Forum"),a("OutboundLink")],1)])]),e._v(" "),a("p",[a("img",{attrs:{src:n(372),alt:""}})]),e._v(" "),a("blockquote",[a("p",[e._v("@ STMS-Lab  IRCAM - CNRS  - Sorbonne Université")])])])}),[],!1,null,null,null);t.default=r.exports}}]);