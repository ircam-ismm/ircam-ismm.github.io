(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{458:function(t,a,e){"use strict";e.r(a);var s=e(65),r=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"max-msp-ecosystem"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#max-msp-ecosystem"}},[t._v("#")]),t._v(" Max / MSP Ecosystem")]),t._v(" "),e("p",[t._v("These sections relate to the developments for the Max/MSP environment (Cycling'74), for audio processing and synthesis, gesture analysis, and interactive machine learning.")]),t._v(" "),e("h2",{attrs:{id:"mubu"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mubu"}},[t._v("#")]),t._v(" "),e("RouterLink",{attrs:{to:"/max-msp/mubu.html"}},[t._v("MuBu")])],1),t._v(" "),e("p",[t._v("The "),e("RouterLink",{attrs:{to:"/max-msp/mubu.html"}},[t._v("MuBu")]),t._v(" page describe the MuBu package for building interactive audio applications using sensors and machine learning.")],1),t._v(" "),e("h2",{attrs:{id:"catart"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#catart"}},[t._v("#")]),t._v(" CataRT")]),t._v(" "),e("p",[t._v("Corpus-based concatenative synthesis in real-time with "),e("RouterLink",{attrs:{to:"/max-msp/catart.html"}},[t._v("CataRT")]),t._v(".")],1),t._v(" "),e("h2",{attrs:{id:"max-externals-for-audio"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#max-externals-for-audio"}},[t._v("#")]),t._v(" Max externals for audio")]),t._v(" "),e("h2",{attrs:{id:"max-externals-for-gesture"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#max-externals-for-gesture"}},[t._v("#")]),t._v(" Max externals for gesture")])])}),[],!1,null,null,null);a.default=r.exports}}]);