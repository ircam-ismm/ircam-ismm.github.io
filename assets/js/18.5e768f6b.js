(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{455:function(a,t,e){"use strict";e.r(t);var i=e(65),r=Object(i.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h1",{attrs:{id:"mubu"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mubu"}},[a._v("#")]),a._v(" MuBu")]),a._v(" "),e("p",[e("strong",[a._v("MuBu")]),a._v(" ("),e("em",[a._v("multi-buffer")]),a._v(") is a Max toolbox for multimodal analysis of sound and motion, sound synthesis and interactive machine learning. It allows to create interactive gesture-based sonic systems, and it is also the base for the "),e("RouterLink",{attrs:{to:"/max-msp/catart.html"}},[a._v("CataRT")]),a._v(" system for Corpus-based Concatenative Synthesis.")],1),a._v(" "),e("h2",{attrs:{id:"download-and-tutorials"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#download-and-tutorials"}},[a._v("#")]),a._v(" Download and Tutorials")]),a._v(" "),e("ul",[e("li",[e("strong",[a._v("Mubu")]),a._v(" is available in the Max "),e("strong",[a._v("Package Manager")]),a._v(" and from the "),e("a",{attrs:{href:"https://forum.ircam.fr/projects/detail/mubu/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Ircam Forum"),e("OutboundLink")],1)]),a._v(" "),e("li",[e("a",{attrs:{href:"https://www.youtube.com/playlist?list=PLt5gV5YpSJ0wbL2zqLRJQcu2XzisW2xAM",target:"_blank",rel:"noopener noreferrer"}},[a._v("MuBu-related video tutorials"),e("OutboundLink")],1)]),a._v(" "),e("li",[e("a",{attrs:{href:"https://forum.ircam.fr/article/detail/tutoriels-mubu/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Video tutorials patches @IrcamForum"),e("OutboundLink")],1)])]),a._v(" "),e("p",[e("strong",[a._v("MuBu")]),a._v(" can be used in different typical use cases:")]),a._v(" "),e("h2",{attrs:{id:"recording-playing-analyzing-and-visualizing-multimodal-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#recording-playing-analyzing-and-visualizing-multimodal-data"}},[a._v("#")]),a._v(" Recording, Playing, Analyzing and Visualizing Multimodal Data")]),a._v(" "),e("ul",[e("li",[a._v("audio and audio descriptors")]),a._v(" "),e("li",[a._v("sensors data and motion descriptors")]),a._v(" "),e("li",[a._v("MIDI")]),a._v(" "),e("li",[a._v("temporal markers")])]),a._v(" "),e("h2",{attrs:{id:"real-time-processing-of-audio-and-sensor-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#real-time-processing-of-audio-and-sensor-data"}},[a._v("#")]),a._v(" Real-time Processing of Audio and Sensor Data")]),a._v(" "),e("ul",[e("li",[a._v("filtering")]),a._v(" "),e("li",[a._v("segmentation")]),a._v(" "),e("li",[a._v("computing descriptors (pitch, timbre, FFT, MFCC, wavelets, statistic)")])]),a._v(" "),e("h2",{attrs:{id:"interactive-machine-learning"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#interactive-machine-learning"}},[a._v("#")]),a._v(" Interactive Machine Learning")]),a._v(" "),e("ul",[e("li",[a._v("KNN (k-nearest neighbours search)")]),a._v(" "),e("li",[a._v("PCA (principal component analysis)")]),a._v(" "),e("li",[a._v("GMM (Gaussian mixture model recognition), GMR (regression)")]),a._v(" "),e("li",[a._v("HMM (hidden Markov model recognition), XMM (regression);")]),a._v(" "),e("li",[a._v("DTW (dynamic time warping)")]),a._v(" "),e("li",[a._v("Gesture following (GF) and Gesture Variation Following")])]),a._v(" "),e("h2",{attrs:{id:"interactive-sound-synthesis"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#interactive-sound-synthesis"}},[a._v("#")]),a._v(" Interactive Sound Synthesis")]),a._v(" "),e("ul",[e("li",[a._v("Granular synthesis")]),a._v(" "),e("li",[a._v("Concatenative synthesis")]),a._v(" "),e("li",[a._v("Additive synthese")])]),a._v(" "),e("blockquote",[e("p",[a._v("License: Forum (Toolbox distributed freely, proprietary code)")])])])}),[],!1,null,null,null);t.default=r.exports}}]);