(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{372:function(e,t,s){e.exports=s.p+"assets/img/research-areas-illustration.d15e088f.jpg"},448:function(e,t,s){"use strict";s.r(t);var a=s(65),r=Object(a.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"research-areas"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#research-areas"}},[e._v("#")]),e._v(" Research Areas")]),e._v(" "),a("p",[a("img",{attrs:{src:s(372),alt:""}})]),e._v(" "),a("p",[e._v("The "),a("em",[e._v("{Sound Music Movement Interaction}")]),e._v(" team (previously known as the "),a("em",[e._v("Real-Time Musical Interactions")]),e._v(" team) carries out research and development on interactive systems dedicated to music and performances. Our work relates to all aspects of the interactive process, including the capture and multimodal analysis of the gestures and sounds created by musicians, tools for the synchronization and management of interaction, as well as techniques for real-time synthesis and sound processing.")])])}),[],!1,null,null,null);t.default=r.exports}}]);